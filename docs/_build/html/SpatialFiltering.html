
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>3. Spatial filtering using ENVI 5.2 &#8212; GEOG0027 Environmental Remote Sensing 1.0.2019 documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="4. Classification using ENVI 5.2" href="ClassificationIntro.html" />
    <link rel="prev" title="2. Download data" href="Download.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput div.prompt,
div.nbinput div.input_area,
div.nbinput div[class*=highlight],
div.nbinput div[class*=highlight] pre,
div.nboutput,
div.nbinput div.prompt,
div.nbinput div.output_area,
div.nboutput div[class*=highlight],
div.nboutput div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput,
    div.nboutput {
        flex-direction: column;
    }
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput div.prompt,
div.nboutput div.prompt {
    min-width: 5ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput div.prompt,
    div.nboutput div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput div.prompt pre,
div.nboutput div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput div.input_area,
div.nboutput div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput div.input_area,
    div.nboutput div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<div class="section" id="Spatial-filtering-using-ENVI-5.2">
<h1>3. Spatial filtering using ENVI 5.2<a class="headerlink" href="#Spatial-filtering-using-ENVI-5.2" title="Permalink to this headline">¶</a></h1>
<p>Prof. P. Lewis &amp; Dr. M. Disney</p>
<p>Remote Sensing Unit</p>
<p>Dept. Geography</p>
<p>UCL</p>
<div class="section" id="Aims">
<h2>3.1. Aims<a class="headerlink" href="#Aims" title="Permalink to this headline">¶</a></h2>
<p>After completing this practical, you should be able to answer the questions: Which type of filter should I use for a given filtering application? What impact will the size and shape of the filter have on the output? You should have some understanding of the process (and issues) of spatial filtering of EO data using Envi.</p>
</div>
<div class="section" id="Advanced-use-of-these-notes">
<h2>3.2. Advanced use of these notes<a class="headerlink" href="#Advanced-use-of-these-notes" title="Permalink to this headline">¶</a></h2>
<p>Although it is perfectly adequate to simply view the html (webpage) of these notes, there are some additional features in these notes that you can use (in this case, a convolution tool with sliders) if you access them in a different way. The reason this is possible is that these notes are written in an <a class="reference external" href="http://ipython.org/notebook.html">ipython notebook</a>.</p>
<p>To use the notes as a notebook (assuming you have <code class="docutils literal notranslate"><span class="pre">`git</span></code> &lt;<a class="reference external" href="http://git-scm.com">http://git-scm.com</a>&gt;`__ and <a class="reference external" href="http://continuum.io/downloads">python</a> on your computer):</p>
<ol class="arabic">
<li><p class="first">Copy all of the notes to your local computer (<strong>if for the first time</strong>)</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mkdir</span> <span class="o">-</span><span class="n">p</span> <span class="o">~/</span><span class="n">DATA</span><span class="o">/</span><span class="n">working</span>
<span class="n">cd</span> <span class="o">~/</span><span class="n">DATA</span><span class="o">/</span><span class="n">working</span>

<span class="n">git</span> <span class="n">clone</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">profLewis</span><span class="o">/</span><span class="n">geog2021</span><span class="o">.</span><span class="n">git</span>

<span class="n">cd</span> <span class="n">geog2021</span>
</pre></div>
</div>
</li>
<li><p class="first">Copy all of the notes to your local computer (<strong>if for an update</strong>)</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="o">~/</span><span class="n">DATA</span><span class="o">/</span><span class="n">working</span><span class="o">/</span><span class="n">geog2021</span>

<span class="n">git</span> <span class="n">reset</span> <span class="o">--</span><span class="n">hard</span> <span class="n">HEAD</span>

<span class="n">git</span> <span class="n">pull</span>
</pre></div>
</div>
</li>
<li><p class="first">Run the notebook</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ipython</span> <span class="n">notebook</span> <span class="n">SpatialFiltering</span><span class="o">.</span><span class="n">ipynb</span>
</pre></div>
</div>
</li>
</ol>
</div>
<div class="section" id="Contents">
<h2>3.3. Contents<a class="headerlink" href="#Contents" title="Permalink to this headline">¶</a></h2>
<p>[<a class="reference external" href="#Image-Display-and-Enhancement-using-ENVI-5.2">top</a>][<a class="reference external" href="#1.-Introduction">Introduction</a>] [<a class="reference external" href="#2.-Convolution-filtering">Convolution Filtering</a>][<a class="reference external" href="#3.-Convolution">1D Convolution</a>] [<a class="reference external" href="#4.-Extras">Extras</a>][<a class="reference external" href="#5.-Summary">Summary</a>]</p>
</div>
<div class="section" id="Data">
<h2>3.4. Data<a class="headerlink" href="#Data" title="Permalink to this headline">¶</a></h2>
<p>The datasets you need for this practical are available from:</p>
<ul class="simple">
<li><a class="reference external" href="https://github.com/profLewis/geog2021/blob/master/practical1/ETM-190600">ETM-190600</a></li>
<li><a class="reference external" href="https://github.com/profLewis/geog2021/blob/master/practical1/ETM-190600.HDR">ETM-190600.HDR</a></li>
<li><a class="reference external" href="https://github.com/profLewis/geog2021/blob/master/practical1/TM-280589">TM-280589</a></li>
<li><a class="reference external" href="https://github.com/profLewis/geog2021/blob/master/practical1/TM-280589.HDR">TM-280589.HDR</a></li>
</ul>
<p>You should download these data and put them in a directory (folder) that you will remember!</p>
<p>The data you will be using are:</p>
<ul class="simple">
<li>six wavebands of a Landsat TM image over Greater London, imaged on May 28th 1989. The data were obtained from the GLCF which maintains a large database of (freely available) Landsat and other imagery. The data are at an original pixel spacing of 28.5 m, but have been resampled to a 25 m grid here. The data are in a Transverse Mercator projection with OSGB 1936 datum.</li>
<li>six wavebands (nominally the same wavelengths) of a Landsat ETM image with 25 m spatial resolution, covering the same spatial extent. These data were obtained on June 19th 2000. The data were obtained from Landmap which contains a database available to Universities and other users through an Athens login (done via the institution you are at).</li>
</ul>
<p>The wavebands are:</p>
<table border="1" class="docutils">
<colgroup>
<col width="16%" />
<col width="16%" />
<col width="16%" />
<col width="16%" />
<col width="18%" />
<col width="18%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">1</th>
<th class="head">2</th>
<th class="head">3</th>
<th class="head">4</th>
<th class="head">5</th>
<th class="head">6</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>450-520 nm</td>
<td>520-600 nm</td>
<td>630-690 nm</td>
<td>760-900 nm</td>
<td>1550-1750 nm</td>
<td>2080-2350 nm</td>
</tr>
</tbody>
</table>
<p>The extent of the imagery is (Lat/Lon):</p>
<div class="math notranslate nohighlight">
\[51^o 43'   9.23'' North, 0^o 36' 18.37'' West\]</div>
<p>to</p>
<div class="math notranslate nohighlight">
\[51^o 16' 29.32'' North,  0^o 27' 24.60'' East\]</div>
</div>
<div class="section" id="1.-Introduction">
<h2>3.5. 1. Introduction<a class="headerlink" href="#1.-Introduction" title="Permalink to this headline">¶</a></h2>
<p><strong>*In this section, we load the image data we wish to explore*</strong>.</p>
<p>The purpose of this practical is for you to build on practical 1 and learn about the process of spatial (convolution) filtering.</p>
<p>Note that convolution is a mathematical operation involving the modification of one function by another to produce a third (output) function. In spatial fitering this implies the operation of a filter (one function) on an input image (another function) to produce a filtered image (the output).</p>
<p>The session will be normally run as one two hour supervised practical. You may not complete all tasks in detail in that time, so once you get the hang of how to use the tools, move on to the next section and return later to think more about the remote sensing.</p>
<p>There is a good material for this in text books (e.g. Jensen, Curran etc.) and some of this is online e.g. much of the Jensen material.</p>
<p>First, obtain and then load the <code class="docutils literal notranslate"><span class="pre">TM</span></code> and <code class="docutils literal notranslate"><span class="pre">ETM</span></code> images of London that we used in a previous practical.</p>
<p><strong>View the ETM image as a FCC.</strong></p>
<p><img alt="image0" src="_images/profiles.png" /></p>
</div>
<div class="section" id="2.-Convolution-filtering">
<h2>3.6. 2. Convolution filtering<a class="headerlink" href="#2.-Convolution-filtering" title="Permalink to this headline">¶</a></h2>
<p><strong>*In this section, we use various tools for image convolution*</strong>.</p>
<p>A description of the various options for convolution and morphology are as <a class="reference external" href="http://www.exelisvis.com/docs/ConvolutionMorphologyFilters.html">envi help pages</a>. You should have a quick read over this if you are not familiar with the types of filter we will be using.</p>
<p>These operations are available via the <code class="docutils literal notranslate"><span class="pre">Toolbox</span></code> menu:</p>
<p><img alt="image0" src="_images/profiles.png" /></p>
<p><img alt="image1" src="_images/transdd.png" /></p>
<p><strong>*Apply a high pass filter (the one shown above) to the dataset*</strong></p>
<p>Now Display this and the original dataset using ‘two vertical views’ with the colvolution result in the left.</p>
<p>You should then ‘geo-link’ the two views, so that moving around or zooming in one view is performed the same for both views.</p>
<p><img alt="image2" src="_images/profile3.png" /></p>
<p><strong>*Make sure you make notes of what you have done and how you have done it so you can recall this later.*</strong></p>
<p>Now, find an interesting part of the image, for example Richmond Park, and try to understand how the filter is operating over the features you see.</p>
<p>You might find it easiest to use a greyscale image for this rather than false or real colour.</p>
<p><img alt="image3" src="_images/richmond1.png" /></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># Don&#39;t worry about this -- its just to display the google maps
from IPython.display import HTML
HTML(&#39;&lt;iframe src=gm.html width=100% height=350&gt;&lt;/iframe&gt;&#39;)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<iframe src=gm.html width=100% height=350></iframe></div>
</div>
<p>You may find it useful to examine horizontal or vertical profiles of the original satellite data:</p>
<p><img alt="image0" src="_images/profiles.png" /></p>
<p>You may need to zoom in to the image to see the detail of the transect, but what you should be interested in examining is the relationship between features in the original dataset and the high-pass dataset.</p>
<p>For instance, looking at the NIR band, for a transect going over Richmond Park we see higher DN over the park than surrounding (urban) areas (<strong>why?</strong>) in the original data. In the corresponding high pass filtered dataset (below), we see variation in the filtered result around zero, with some ‘larger’ features (spikes).</p>
<p>Consider carefully the numerical values in the convolution kernel:</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td>-1</td>
<td>-1</td>
<td>-1</td>
</tr>
<tr class="row-even"><td>-1</td>
<td>8</td>
<td>-1</td>
</tr>
<tr class="row-odd"><td>-1</td>
<td>-1</td>
<td>-1</td>
</tr>
</tbody>
</table>
<p><strong>*What does it indicate when there is a positive (or negative) spike in the filtered transect?*</strong></p>
<p><strong>*Why is there a number 8 in the centre of the filter?*</strong></p>
<p><strong>*what does the filter produce if the image data are constant? (‘flat’)*</strong></p>
<p><strong>*what does the filter produce if the image data show a step change? (see e.g. resevoirs)*</strong></p>
<p><img alt="image1" src="_images/transdd.png" /></p>
<p><img alt="image2" src="_images/profile3.png" /></p>
</div>
<div class="section" id="3.-Convolution">
<h2>3.7. 3. Convolution<a class="headerlink" href="#3.-Convolution" title="Permalink to this headline">¶</a></h2>
<p>To think some more about this, it can be instructive to consider filtering in one dimension (rather than the two dimensions of an image). To aid this, we can consider some prototype ‘shapes’ and look at how ther respond under the filtering operation.</p>
<p>Typical example would be step and ramp features.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[129]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>%matplotlib inline
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[130]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>run python/proto.py
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/SpatialFiltering_21_0.png" src="_images/SpatialFiltering_21_0.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/SpatialFiltering_21_1.png" src="_images/SpatialFiltering_21_1.png" />
</div>
</div>
<p>Two basic operations we can perform are looking at the <em>local average</em> (e.g. mean) or <em>local difference</em> with a convolution operator.</p>
<p>For a local mean over extent 3, we would use</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td>0.333</td>
<td>0.333</td>
<td>0.333</td>
</tr>
</tbody>
</table>
<p><strong>*What do the numbers add up to? why is that so*</strong></p>
<p><strong>*what would a filter of extent 7 look like?*</strong></p>
<p>We would expect the local mean to provide some ‘smoothing’ of the function:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[131]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>run python/protoLow.py
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
filter [0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/SpatialFiltering_23_1.png" src="_images/SpatialFiltering_23_1.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/SpatialFiltering_23_2.png" src="_images/SpatialFiltering_23_2.png" />
</div>
</div>
<p>an we can see that this is the case in the illustration (filter width 7) the impact (of smoothing) on the ‘clean’ signals is mostly negligible (which is an effect we would want), and for the noisy datasets, the noise is reduced.</p>
<p>We can also note some ‘edge effects’ (e.g. the step at x = 100):</p>
<p>*** why do these occur?***</p>
<p><strong>*does the extent of the edge effects depend on the extent of the filter? If so, why*</strong></p>
<p><strong>*what might be done to mitigate such effects?*</strong></p>
<p>A local mean (low pass) filter then, such as that shown above reduces the high frequency components of the signal and retains the low frequency components (so we can ‘get rid of’ (reduce)) random noise in the signal.</p>
<p>A local mean is effectively a local <em>integration</em> of the signal.</p>
<p>The ‘opposite’ of this is differentiation, i.e. the difference between one pixel value and the next.</p>
<p>The simplest filter for this is:</p>
<table border="1" class="docutils">
<colgroup>
<col width="45%" />
<col width="55%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td>1</td>
<td>-1</td>
</tr>
</tbody>
</table>
<p>which we can call a first order difference filter.</p>
<p><strong>*what do the values in the filter add up to in this case?*</strong></p>
<p><strong>*why is this so?*</strong></p>
<p>The impact of this is illustrated below.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[196]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>run python/protoHi1.py
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
filter [1.0, -1.0]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/SpatialFiltering_26_1.png" src="_images/SpatialFiltering_26_1.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/SpatialFiltering_26_2.png" src="_images/SpatialFiltering_26_2.png" />
</div>
</div>
<p><strong>*Think through *why* it has the impact that we see.</strong>*</p>
<p><strong>*Of what use might such a filter be?*</strong></p>
<p>If we convolve the first order differential filter:</p>
<table border="1" class="docutils">
<colgroup>
<col width="45%" />
<col width="55%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td>1</td>
<td>-1</td>
</tr>
</tbody>
</table>
<p>we get a <em>second order differential filter</em></p>
<table border="1" class="docutils">
<colgroup>
<col width="31%" />
<col width="38%" />
<col width="31%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td>1</td>
<td>-2</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>Whereas the first filter represents the ‘rate of change’ (e.g. slope) of the signal, the second order filter gives the rate of change of the rate of change (rate of change of slope).</p>
<p><strong>*what do the values in the filter add up to in this case?*</strong></p>
<p><strong>*why is this so?*</strong></p>
<p>To illustrate this:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[133]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>filt = [1.0,-1.0]
print np.convolve(filt,filt)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[ 1. -2.  1.]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[134]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>run python/protoHi2.py
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
filter [1.0, -2.0, 1.0]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/SpatialFiltering_30_1.png" src="_images/SpatialFiltering_30_1.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/SpatialFiltering_30_2.png" src="_images/SpatialFiltering_30_2.png" />
</div>
</div>
<p>At first sight, this might look quite similar to the result of the first order differential.</p>
<p>However, if we look more closely:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[135]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>run python/protoHi2zoom.py
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
filter [1.0, -2.0, 1.0]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/SpatialFiltering_32_1.png" src="_images/SpatialFiltering_32_1.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/SpatialFiltering_32_2.png" src="_images/SpatialFiltering_32_2.png" />
</div>
</div>
<p>we see e.g. that the ‘edge’ of the step edge is mapped to a ‘zero crossing’ in this case, rather than a local maximum as was the case for the first order filter.</p>
<p>The peak of the ramp shows a small negative value in the second order differential data: <strong>*why is this so?*</strong></p>
<p><strong>*What would the result look like if we were to replace the step and ramp functions by one minus step and one minus ramp?*</strong></p>
<p>As a final example, let us consider what happens if we <em>smooth</em> (low pass) and then <em>differentiate</em> (high pass):</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[136]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># show the result of convolving one filter with another filter
filt1 = [1.0,-1.0]
w = 3
filt2 = [1./w]*w
print &#39;differential&#39;,str([&#39;%4.2f&#39;%i for i in filt1]).replace(&quot;&#39;&quot;,&#39;&#39;)
print &#39;smoother    &#39;,str([&#39;%4.2f&#39;%i for i in filt2]).replace(&quot;&#39;&quot;,&#39;&#39;)
conv = np.convolve(filt1,filt2,&#39;full&#39;)
print &#39;combined    &#39;,str([&#39;%4.2f&#39;%i for i in conv]).replace(&quot;&#39;&quot;,&#39;&#39;)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
differential [1.00, -1.00]
smoother     [0.33, 0.33, 0.33]
combined     [0.33, 0.00, 0.00, -0.33]
</pre></div></div>
</div>
<p>Applying two filters to an image/signal has the same effect as convolving the two filters together and then applying this.</p>
<p>We see that convolving a filter of extent 2 with one of extent 3 gives a new filter of extent 4. <strong>*Why is this so?*</strong></p>
<p>To demonstrate, in the plots below, we first convolve the step and ramp with <code class="docutils literal notranslate"><span class="pre">filter</span> <span class="pre">1</span></code> (<strong>*what type of filter is this?*</strong>) (blue line), then convolve this with <code class="docutils literal notranslate"><span class="pre">filter</span> <span class="pre">2</span></code> (<strong>*what type of filter is this?*</strong>) (green line). Applying the combined filter to the data, we get the dashed red line (which is the same as the green line).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[137]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>run python/protoHiLow.py
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
filter 1:         [1.00, -2.00, 1.00]
filter 2:         [0.14, 0.14, 0.14, 0.14, 0.14, 0.14, 0.14]
combined filter:  [0.14, -0.14, 0.00, 0.00, 0.00, 0.00, 0.00, -0.14, 0.14]
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/SpatialFiltering_37_1.png" src="_images/SpatialFiltering_37_1.png" />
</div>
</div>
<p>Thinking through these graphs should re-inforrce what you have learned about spatial convolution in the lectures. You should be able to describe what the impact of different forms of filter on such prototype functions would be. You should then be able to translate this knowledge back to examining the image data.</p>
<p><strong>*Go back to the ``envi`` session and examine the impact of first and second order differential and smoothing filters on the image data*</strong></p>
<p><strong>*Relate what you see (e.g. in looking in detail at transects) to the impacts on the prototype shapes*</strong></p>
<p><strong>*Of what use might all of this be?*</strong></p>
</div>
<div class="section" id="4.-Extras">
<h2>3.8. 4. Extras<a class="headerlink" href="#4.-Extras" title="Permalink to this headline">¶</a></h2>
<p>If you run these notes as an ipython notebook, then this shows an interactive tool to see the impact of filtering.</p>
<p>You can use the tool to explore the trade-offs you need to consider when filtering: e.g. a wider smoothing filter will suppress a higher level of noise (i.e. do more smoothing) than a narrow filter. However, with a wider filter, you are likely to suffer from greater ‘edge effects’.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[197]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>run python/interact.py
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/SpatialFiltering_41_0.png" src="_images/SpatialFiltering_41_0.png" />
</div>
</div>
</div>
<div class="section" id="5.-Summary">
<h2>3.9. 5. Summary<a class="headerlink" href="#5.-Summary" title="Permalink to this headline">¶</a></h2>
<p>The main aim of this practical is to reinforce your understanding of convolution operationsd using the image processing software tool <code class="docutils literal notranslate"><span class="pre">envi</span></code>.</p>
<p>In this practical, we have loaded Landsat images of London and and examined the application of high and low pass filters.</p>
<p>[<a class="reference external" href="#Image-Display-and-Enhancement-using-ENVI-5.2">top</a>][<a class="reference external" href="#1.-Introduction">Introduction</a>] [<a class="reference external" href="#2.-Convolution-filtering">Convolution Filtering</a>][<a class="reference external" href="#3.-Convolution">1D Convolution</a>] [<a class="reference external" href="#4.-Extras">Extras</a>][<a class="reference external" href="#5.-Summary">Summary</a>]</p>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">GEOG0027 Environmental Remote Sensing</a></h1>








<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="ImageDisplay.html">1. Image Display</a></li>
<li class="toctree-l1"><a class="reference internal" href="Download.html">2. Data Download</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">3. Spatial Filtering</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Aims">3.1. Aims</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Advanced-use-of-these-notes">3.2. Advanced use of these notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Contents">3.3. Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Data">3.4. Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="#1.-Introduction">3.5. 1. Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#2.-Convolution-filtering">3.6. 2. Convolution filtering</a></li>
<li class="toctree-l2"><a class="reference internal" href="#3.-Convolution">3.7. 3. Convolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="#4.-Extras">3.8. 4. Extras</a></li>
<li class="toctree-l2"><a class="reference internal" href="#5.-Summary">3.9. 5. Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="ClassificationIntro.html">4. Classification Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="Classification.html">5. Classification</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="Download.html" title="previous chapter">2. Download data</a></li>
      <li>Next: <a href="ClassificationIntro.html" title="next chapter">4. Classification using ENVI 5.2</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2019, P Lewis.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.8.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.11</a>
      
      |
      <a href="_sources/SpatialFiltering.ipynb.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>