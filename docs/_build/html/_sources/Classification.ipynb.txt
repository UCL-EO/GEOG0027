{
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "name": "",
  "signature": "sha256:6ede76ba5603dbd2cac242b9b9bdce75a7d26bd963349b16461e701430f8f35a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img style=\"float: left\" src=\"images/ucl_logo.png\">\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Classification using ENVI 5.2"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Prof. P. Lewis & Dr. M. Disney\n",
      "\n",
      "Remote Sensing Unit\n",
      "\n",
      "Dept. Geography\n",
      "\n",
      "UCL"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Aims"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After completing this practical, you should be able to analyse one or more image datasets using classification methods. This includes learning to identify land cover classes in a dataset and consider class separability (using histograms, scatterplots and other tools), and applying and assessing a classification product using Envi. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Advanced use of these notes"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Although it is perfectly adequate to simply view the html (webpage) of these notes, there are some additional features in these notes that you can use (in this case, a convolution tool with sliders) if you access them in a different way. The reason this is possible is that these notes are written in an [ipython notebook](http://ipython.org/notebook.html).\n",
      "\n",
      "To use the notes as a notebook (assuming you have [`git`](http://git-scm.com) and [python](http://continuum.io/downloads) on your computer):\n",
      "\n",
      "1. Copy all of the notes to your local computer (**if for the first time**)\n",
      "\n",
      "        mkdir -p ~/DATA/working\n",
      "        cd ~/DATA/working\n",
      "\n",
      "        git clone https://github.com/profLewis/geog2021.git\n",
      "    \n",
      "        cd geog2021\n",
      "    \n",
      "2. Copy all of the notes to your local computer (**if for an update**)\n",
      "\n",
      "        cd ~/DATA/working/geog2021\n",
      "\n",
      "        git reset --hard HEAD\n",
      "    \n",
      "        git pull\n",
      "        \n",
      "3. Run the notebook\n",
      "\n",
      "        ipython notebook Classification.ipynb\n",
      "        \n",
      "      "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Contents"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[[top](#Classification-using-ENVI-5.2)]\n",
      "[[Introduction](ClassificationIntro.html#1.-Introduction)]\n",
      "[[Examination of the data](Classification.html#2.-Examination-of-the-data)]\n",
      "[[Defining spectral classes](Classification.html#3.-Defining-spectral-classes)]\n",
      "[[Image Classification](Classification.html#4.-Image-Classification)]\n",
      "[[Accuracy Assessment](Classification.html#5.-Accuracy-Assessment)]\n",
      "[[Further Work](Classification.html#5.-Further-Work)]\n",
      "[[Summary](Classification.html#5.-Summary)]"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "1. Introduction"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The datasets you need for this practical are available from:\n",
      "\n",
      "\n",
      "* [ETM-110801](https://www.dropbox.com/s/z00xo5uxeeru70n/ETM-110801?dl=0)\n",
      "* [ETM-110801.HDR](https://github.com/profLewis/geog2021/blob/master/data/ETM-110801.HDR)\n",
      "* [TM-250792](https://www.dropbox.com/s/6896izuizbnp6jp/TM-250792?dl=0)\n",
      "* [TM-250792.HDR](https://github.com/profLewis/geog2021/blob/master/data/TM-250792.HDR)\n",
      "* [SRTM-2002](https://www.dropbox.com/s/dt3zvnhrbga18nv/SRTM-2002?dl=0)\n",
      "* [SRTM-2002.HDR](https://github.com/profLewis/geog2021/blob/master/data/TM-250792.HDR)\n",
      "\n",
      "\n",
      "You should download these data and put them in a directory (folder) that you will remember!\n",
      "\n",
      "See [Classification Introduction](ClassificationIntro.html) for more details on the context and datasets.\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "2. Examination of the data\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load up the two images and examine the data. Try to identify the various classes you might like to obtain for this exercise decide how you can identify them. Examine feature space plots (scatter plots) to help you decide what may be feasible (and what may not). **You may decide that transformations of the data (e.g. band ratios or Principal Components) might aid your ability (and the computer's ability) to discriminate between classes**, but you should simply explore the data to start with."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Don't worry about this -- its just to display the google maps\n",
      "from IPython.display import HTML\n",
      "HTML('<iframe src=gmRondoniaZoom.html width=100% height=700></iframe>')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<iframe src=gmRondoniaZoom.html width=100% height=700></iframe>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "<IPython.core.display.HTML at 0x108121c90>"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some examples of the various classes you might consider (shown on a standard False Colour Composite (FCC) image):\n",
      "\n",
      "|Class | Notes | Example |\n",
      "| ---- | ----    | ---- |\n",
      "| **Urban** | May also include other 'built' structures such as roads. You should be able to recognise these from their spatial structure, even at this resolution | [![](images/urban.gif)](images/urban.gif)|\n",
      "| **Forest** | This should be easy to spot, but there are sometime clear 'shading' effects (as in this example) that might complicate classification | [![](images/forest.gif)](images/forest.gif)|\n",
      "| **Rocks** | Rocks are quite easily identifiable in the FCC images. You would generally expect them to be static between the two dates. | [![](images/rocks.gif)](images/rocks.gif)|\n",
      "| **Rivers** | There are rivers and other water bodies in the scene, which you will be able to recognise by their shape. They will be difficult to use as training sites as they are quite narrow at this resolution. | [![](images/rivers.gif)](images/rivers.gif)|\n",
      "| **Farmland** | You will see a broad patchwork of areas that have been cleared of forest and used to graze cattle or raise crops.  The areas a quite easy to spot in the FCC images, but might represent a broad spectral class because of the various physical cover types involved | [![](images/ranch.gif)](images/ranch.gif)|\n",
      "| **Other** | You may spot some areas that have rather different spectral properties to most of the other areas. One example is shown here of field-shaped areas (green and purple areas) that might be inferred to be farmland, but are clearly different spectrally to other areas of farmland. We cannot really determine what these areas are from the information available, so you might require an 'other' class to cope with such eventualities. | [![](images/other.gif)](images/other.gif)|\n",
      "| **Cloud** | The images may contain a small amount of cloud or smoke/haze, an example of which is shown here. They are quite easy to recognise visually in the FCC, but may be difficult to classify unless they are quite thick. If there are any thick clouds, you may see cloud shadows on the ground as well. | [![](images/cloud.gif)](images/cloud.gif)|\n",
      "\n",
      "\n",
      "\n",
      "You may make use of Google Maps to explore detail of the areas, e.g., if you zoom in to the 'rock' area, you will find it is is actually more complex than just 'bare rock':\n",
      "\n",
      "![](images/mymovie.gif)\n",
      "\n",
      "When deciding which classes may be appropriate to use, you should make use of your understanding of histograms and scatterplots, and use these to help explore the image information content."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "3. Defining spectral classes"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to classify the image data you are required to define a set of \"signatures\" which represent each class. These are then used to \"train\" the classification algorithm.\n",
      "\n",
      "In envi, you need to define these classes via ROIs (Regions of Interest). Select the ROI tool:\n",
      "\n",
      "![](images/roi.png)\n",
      "\n",
      "and outline an ROI you want to define with the tool:\n",
      "\n",
      "![](images/roii.png)\n",
      "\n",
      "\n",
      "You may find the ['N-D visualiser'](http://www.exelisvis.com/docs/nDimensionalVisualizer.html) useful when doing this:\n",
      "\n",
      "![](images/send.png)\n",
      "\n",
      "If you select only 2 bands to view, you will see informatyion similar to the scatterplot (i.e. 2-dimensional). \n",
      "\n",
      "![](images/btwo.png)\n",
      "\n",
      "In such a view, you can readily 'see' how separable the classes might be.\n",
      "\n",
      "In higher dimensions, the visualiser 'rotates' the view so you can get different perspectives on the classes\n",
      "\n",
      "![](images/classes.gif)\n",
      "\n",
      "Note that you will want to create an ROI for each class you are interested in, but that yoy can 'merge' (or delete) classes once you have created them.\n",
      "\n",
      "When you think you have a suitable set of ROIs, check the class separability:\n",
      "\n",
      "![](images/sep.png)\n",
      "\n",
      "This outputs Divergence metrics between the classes you have defined. These values range between 0 and 2.0. As a guide to interpretation, values greater than 1.9 indicate good separability of classes. If class separability is less than this, you might consider splitting the classes for the classification and recombining them post-classification (e.g. have two classes: forest1 and forest2).\n",
      "\n",
      "![](images/sep2.png)\n",
      "\n",
      "\n",
      "\n",
      "Then, make sure you save them (to xml format):\n",
      "\n",
      "![](images/myclasses.png)\n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "4. Image Classification"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To perform a classification, first look at the options in the Toolbox:\n",
      "\n",
      "\n",
      "![](images/opt.png)\n",
      "\n",
      "\n",
      "As a first attempt, try the [Maximum Likelihood](http://www.exelisvis.com/docs/MaximumLikelihood.html) classifier.\n",
      "\n",
      "A [Tutorial](http://www.exelisvis.com/portals/0/pdfs/envi/Classification_Methods.pdf) is available that will take you through some of the other options.\n",
      "\n",
      "For the [Maximum Likelihood](http://www.exelisvis.com/docs/MaximumLikelihood.html) classifier, slect this itme from the Toolbox:\n",
      "\n",
      "![](images/load.png)\n",
      "\n",
      "and perform any subsetting or masking that you might require.\n",
      "\n",
      "Then, select the Classes you want from the ROIs you have defined, along with making decisions about whether you want to save the result or not (if not, then just send it to 'memory', but it will not then be saved at the end of the session). If you do save the result, make sure you note down (in your notebook) what the file name was and what settings you used (e.g. which classes). \n",
      "\n",
      "![](images/ml.png)\n",
      "\n",
      "You should now have a classification result:\n",
      "\n",
      "![](images/pink.png)\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is generally very instructive to visualise the 'rule' image associated with a result. This provides you with the reasoning the computer used to obtain the result it did.\n",
      "\n",
      "For a method such as that used above, the training data are used to generate multivariate statistical distributions that we suppose to describe the full class. Each pixel then can be assigned a probability of class membership. The class which has the highest membership probability is usually assigned that class label.\n",
      "\n",
      "![](images/prob.png)\n",
      "\n",
      "What issues might occur if the probability of belonging to more than one class is very similar?\n",
      "\n",
      "There appear to be topographic effects in the class probability images: why would that be so? and what might you do about it?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "5. Accuracy Assessment"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is not very difficult to produce a classified map using earth observation data. You have now been through the process ofsupervised classification (using one method).\n",
      "\n",
      "How can we tell how good this is though?\n",
      "\n",
      "One thing you may wish to do is to examine the post-classification class statistics:\n",
      "\n",
      "![](images/post.png)\n",
      "\n",
      "There are various other options that you may find useful to explore in the Post Classification section of the toolbox."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A vital part of the classification process though is an assessment of classification accuracy.\n",
      "\n",
      "This is generally done as a [confusion matrix](http://www.exelisvis.com/docs/CalculatingConfusionMatrices.html).\n",
      "\n",
      "In setting this up, you need either to have a ground truth 'image', or a set of ROIs that can be used for ground truth.\n",
      "\n",
      "You should first generate a new (independent) set of ROIs (or better still, use random samples) for your classes. If you use random samples, you can check what you think the land cover class should be using Google Earth/Maps as above.\n",
      "\n",
      "Once you have your confusion matrix, make sure that you understand what it is telling you (and as far as possible, why that is so).\n",
      "\n",
      "If the classification result seems poor, you can go back and edit your settings or class definitions and re-try, but try to keep the ROIs you use for checking independent of this process.\n",
      "\n",
      "Make sure you understand the terms we use to describe the different accuracies shown in the confusion matrix, and also [what a kappa coefficient is](http://www.exelisvis.com/docs/CalculatingConfusionMatrices.html)."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "6. Further Work"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this practical, you have gone through the process of performing an image classification and assessing its accuracy.\n",
      "\n",
      "To finish the practical, you should classify *both* of the Landsat datasets you have, and calculate the change in forest area between the two dates. Since you have an accuracy assessment, it should be feasible for you to put an uncertainty on that estimate of change."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "7. Summary"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The main aim of this practical is to reinforce your understanding of the classification process and for you to gain practical experience at this.\n",
      "\n",
      "It would be worthwhile exploring some of the options you have available (e.g. try some different classifiers).\n",
      "\n",
      "Since there is quite a lot of 'button clicking' in this exercise, *make sure* that you understand what you are doing and why you are getting the result you do -- there is very little value in the exercise otherwise!\n",
      "\n",
      "If you have questions, ask the staff!\n",
      "\n",
      "If you are very interested in change detection, you could explore the [change detection options in ENVI](http://www.exelisvis.com/docs/ChangeDetectionAnalysis.html)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[[top](#Classification-using-ENVI-5.2)]\n",
      "[[Introduction](ClassificationIntro.html#1.-Introduction)]\n",
      "[[Examination of the data](Classification.html#2.-Examination-of-the-data)]\n",
      "[[Defining spectral classes](Classification.html#3.-Defining-spectral-classes)]\n",
      "[[Image Classification](Classification.html#4.-Image-Classification)]\n",
      "[[Accuracy Assessment](Classification.html#5.-Accuracy-Assessment)]\n",
      "[[Further Work](Classification.html#5.-Further-Work)]\n",
      "[[Summary](Classification.html#5.-Summary)]"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}